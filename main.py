# File: run.py
# Description: Hyperparameter search script for the TWO-STAGE EGAE-GAT model.

import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
import itertools
import os
import time
import seaborn as sns
import traceback

# å…³é”®ï¼šä»æ‚¨çš„æ¨¡å‹æ–‡ä»¶ä¸­å¯¼å…¥ä¸¤ä¸ªé˜¶æ®µæ¨¡å‹å’ŒKNNæ„å›¾å‡½æ•°
# è¯·ç¡®ä¿æ‚¨çš„æ¨¡å‹æ–‡ä»¶åä¸æ­¤å¤„åŒ¹é…ï¼ˆä¾‹å¦‚ï¼Œegae_gat_two_stage.pyï¼‰
from model import C_MSGFC, construct_knn_graph
from utils import load_data

warnings.filterwarnings('ignore')

# å…¨å±€åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ‰€æœ‰å®éªŒçš„ç»“æœ
results = []


def run_single_experiment(
        # æ–°å¢ï¼šç¬¬ä¸€é˜¶æ®µå’Œå›¾ç²¾ç‚¼çš„å‚æ•°
        stage1_epochs,
        knn_k,
        # ç¬¬äºŒé˜¶æ®µçš„å‚æ•° (åŸå§‹å‚æ•°)
        alpha,
        coeff_reg,
        lr,
        layers,
        activation_func,
        max_epoch,
        # é€šç”¨å‚æ•°
        dataset_name,
        save_dir):
    """
    è¿è¡Œä¸€ä¸ªå®Œæ•´çš„ã€éµå¾ªåŒé˜¶æ®µæ¶æ„çš„è®­ç»ƒå®éªŒã€‚
    """
    # åˆ›å»ºä¸€ä¸ªå¯¹æ–‡ä»¶åå®‰å…¨é…ç½®å­—ç¬¦ä¸²
    config_str_safe = (f"s1ep{stage1_epochs}_knn{knn_k}_alpha{alpha}_reg{coeff_reg}_lr{lr}_"
                       f"layers{'-'.join(map(str, layers))}_act{activation_func.__name__}")

    print(f"\n{'=' * 80}\nğŸš€ Running experiment: {config_str_safe} on '{dataset_name}'\n{'=' * 80}")

    try:
        model_save_dir = os.path.join(save_dir, 'saved_models')
        os.makedirs(model_save_dir, exist_ok=True)
        # ç¬¬äºŒé˜¶æ®µæ¨¡å‹çš„ä¿å­˜è·¯å¾„
        best_model_path = os.path.join(model_save_dir, f'best_model_{config_str_safe}.pth')

        features, adjacency, labels = load_data(dataset_name)
        acts = [activation_func] * (len(layers) - 1) + [None]
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        start_time = time.time()

        # --- æ­¥éª¤ 1: è®­ç»ƒç¬¬ä¸€é˜¶æ®µæ¨¡å‹ä»¥å­¦ä¹ åˆå§‹è¡¨ç¤º Zâ‚ ---
        print("--- Step 1: Training Stage 1 Model to get Zâ‚ ---")
        model_stage1 = C_MSGFC(
            X=features, A=adjacency, labels=labels, alpha=0,  # Alphaä¸º0ï¼Œä¸è¿›è¡Œèšç±»
            layers=layers, acts=acts, learning_rate=lr, coeff_reg=coeff_reg, device=device
        )
        # ä½¿ç”¨ç¬¬ä¸€é˜¶æ®µä¸“å±çš„è®­ç»ƒå‡½æ•°
        z1_embedding = model_stage1.train_stage1(epochs=stage1_epochs, learning_rate=lr)

        # --- æ­¥éª¤ 2: ä½¿ç”¨ Zâ‚ è¿›è¡Œå›¾ç»“æ„ç²¾ç‚¼ (KNN) ---
        print(f"--- Step 2: Refining graph structure with KNN (k={knn_k}) ---")
        refined_adjacency = construct_knn_graph(features=z1_embedding, k=knn_k, device=device)

        # --- æ­¥éª¤ 3: è®­ç»ƒç¬¬äºŒé˜¶æ®µæ¨¡å‹ï¼Œä½¿ç”¨ç²¾ç‚¼åçš„å›¾ ---
        print("--- Step 3: Training Stage 2 Model with the refined graph ---")
        model_stage2 = C_MSGFC(
            X=features, A=refined_adjacency, labels=labels, alpha=alpha,  # ä½¿ç”¨ç²¾ç‚¼å›¾å’ŒæŒ‡å®šçš„alpha
            layers=layers, acts=acts, max_epoch=max_epoch,
            learning_rate=lr, coeff_reg=coeff_reg, device=device
        )

        # è°ƒç”¨å®Œæ•´çš„è”åˆä¼˜åŒ–è®­ç»ƒæµç¨‹ `run`
        # ä¿®æ­£ï¼šrunæ–¹æ³•ç°åœ¨æ­£ç¡®è¿”å›4ä¸ªå€¼
        acc, nmi, ari, f1 = model_stage2.run(
            return_final_metrics=True,
            best_model_path=best_model_path,
            warmup_epoch=10  # å¯ä»¥è®¾ä¸ºä¸€ä¸ªè¶…å‚æ•°
        )
        training_time = time.time() - start_time

        results.append({
            'dataset': dataset_name, 'stage1_epochs': stage1_epochs, 'knn_k': knn_k,
            'alpha': alpha, 'coeff_reg': coeff_reg, 'lr': lr,
            'layers': str(layers), 'activation': activation_func.__name__,
            'ACC': acc, 'NMI': nmi, 'ARI': ari, 'F1': f1,
            'training_time': training_time, 'status': 'Success'
        })

    except Exception as e:
        print(f"âš ï¸ An error occurred during experiment: {config_str_safe}")
        traceback.print_exc()
        results.append({
            'dataset': dataset_name, 'stage1_epochs': stage1_epochs, 'knn_k': knn_k,
            'alpha': alpha, 'coeff_reg': coeff_reg, 'lr': lr,
            'layers': str(layers), 'activation': activation_func.__name__,
            'ACC': np.nan, 'NMI': np.nan, 'ARI': np.nan, 'F1': np.nan,
            'training_time': np.nan, 'status': f'Error: {e}'
        })


def analyze_and_save_summary(df, save_dir, dataset_name):
    """
    åˆ†æå®éªŒç»“æœï¼Œæ‰“å°æ€»ç»“å¹¶ä¿å­˜åˆ°æ–‡ä»¶ã€‚
    ï¼ˆæ­¤å‡½æ•°å·²æ›´æ–°ä»¥æ˜¾ç¤ºæ–°çš„è¶…å‚æ•°ï¼‰
    """
    summary_path = os.path.join(save_dir, 'best_configs_summary.txt')

    df_success = df[df['status'] == 'Success'].copy()
    if df_success.empty:
        message = "No successful runs were completed to analyze."
        print(message)
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(message)
        return

    summary_lines = []
    header = "=" * 80
    title = f"ğŸ† Best Configurations Found for '{dataset_name}' (Two-Stage Model)"
    summary_lines.append(header)
    summary_lines.append(title)

    metrics_to_analyze = ['ACC', 'NMI', 'ARI', 'F1']
    for metric in metrics_to_analyze:
        df_success[metric] = pd.to_numeric(df_success[metric], errors='coerce')
        if not df_success[metric].dropna().empty:
            best_config = df_success.loc[df_success[metric].idxmax()]
            summary_lines.append(f"\nâ­ Best by {metric}: {best_config[metric]:.4f}")
            # ä»è¦æ‰“å°çš„ç³»åˆ—ä¸­åˆ é™¤ä¸å¿…è¦çš„ä¿¡æ¯
            cols_to_drop = ['status', 'training_time', 'dataset']
            summary_lines.append(best_config.drop(cols_to_drop).to_string())

    summary_lines.append("\n" + header)
    final_summary = "\n".join(summary_lines)

    print("\n" + final_summary)
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write(final_summary)
    print(f"\nğŸ“„ Summary saved to '{summary_path}'")


def plot_search_results(df, save_dir):
    """
    ç”Ÿæˆå¹¶ä¿å­˜å¯è§†åŒ–è¶…å‚æ•°å½±å“çš„å›¾è¡¨ã€‚
    ï¼ˆæ­¤å‡½æ•°å·²æ›´æ–°ä»¥ç»˜åˆ¶æ–°çš„è¶…å‚æ•°ï¼‰
    """
    print("\nğŸ“Š Plotting search results...")
    plot_dir = os.path.join(save_dir, 'plots')
    os.makedirs(plot_dir, exist_ok=True)
    df_success = df[df['status'] == 'Success'].copy()
    if df_success.empty:
        print("No successful experiments to plot.")
        return

    # ç¡®ä¿åˆ—æ˜¯æ­£ç¡®çš„æ•°å€¼ç±»å‹
    for col in ['alpha', 'lr', 'knn_k', 'stage1_epochs', 'ACC', 'NMI', 'ARI', 'F1']:
        df_success[col] = pd.to_numeric(df_success[col], errors='coerce')

    metrics_to_plot = ['ACC', 'NMI', 'ARI', 'F1']
    # å°†æ–°å‚æ•°åŠ å…¥åˆ†æåˆ—è¡¨
    params_to_analyze = ['alpha', 'lr', 'layers', 'activation', 'knn_k', 'stage1_epochs']

    for metric in metrics_to_plot:
        for param in params_to_analyze:
            plt.figure(figsize=(12, 7))
            # ä½¿ç”¨ç®±çº¿å›¾æˆ–ç‚¹å›¾æ›´é€‚åˆåˆ†ç±»å’Œæ•´æ•°å‚æ•°
            if param in ['layers', 'activation']:
                sns.boxplot(data=df_success, x=param, y=metric)
            else:
                sns.lineplot(data=df_success, x=param, y=metric, marker='o', errorbar='sd')

            plt.title(f'{metric} vs {param.capitalize()} (Two-Stage Model)')
            plt.ylabel(metric)
            plt.xlabel(param.capitalize())
            plt.grid(True, which='both', linestyle='--')
            if param in ['layers', 'activation']:
                plt.xticks(rotation=15, ha='right')
            plt.tight_layout()
            plt.savefig(os.path.join(plot_dir, f'{metric}_vs_{param}.png'))
            plt.close()
    print(f"Plots saved to '{plot_dir}'")


def main():
    """
    ä¸»å‡½æ•°ï¼Œå®šä¹‰è¶…å‚æ•°ç©ºé—´å¹¶è¿è¡Œæœç´¢ã€‚
    """
    # --- æ ¸å¿ƒé…ç½® ---
    dataset_name = 'hhar'  # åœ¨æ­¤åˆ‡æ¢æ•°æ®é›†: 'cora', 'citeseer', 'acm', 'dblp'
    save_dir = f'hyperparam_search_2stage_{dataset_name}_{time.strftime("%Y%m%d-%H%M%S")}'
    os.makedirs(save_dir, exist_ok=True)

    # --- å®šä¹‰æ‰©å±•åçš„è¶…å‚æ•°æœç´¢ç©ºé—´ ---
    # é˜¶æ®µä¸€å’Œå›¾ç²¾ç‚¼çš„å‚æ•°
    stage1_epochs_list = [100,150]
    knn_k_list = [10, 15, 20]

    # é˜¶æ®µäºŒçš„å‚æ•°
    alpha_list = [5, 10, 20]
    coeff_reg_list = [1e-5, 1e-4, 1e-3]
    lr_list = [0.0005, 0.001, 0.005]
    max_epoch_list = [200]  # ç¬¬äºŒé˜¶æ®µçš„æ€»è½®æ•°
    layer_options = [[256, 128], [256, 128, 64]]
    activation_options = [F.relu, torch.tanh]

    # ä½¿ç”¨ itertools.product åˆ›å»ºæ‰€æœ‰å¯èƒ½çš„ç»„åˆ
    search_space = list(itertools.product(
        stage1_epochs_list,
        knn_k_list,
        alpha_list,
        coeff_reg_list,
        lr_list,
        layer_options,
        activation_options,
        max_epoch_list
    ))

    total_experiments = len(search_space)
    print(f"ğŸ”¬ Starting two-stage hyperparameter search for '{dataset_name}' with {total_experiments} combinations...")

    total_start_time = time.time()

    for i, params in enumerate(search_space):
        print(f"\n--- Running Combination {i + 1}/{total_experiments} ---")
        run_single_experiment(
            stage1_epochs=params[0],
            knn_k=params[1],
            alpha=params[2],
            coeff_reg=params[3],
            lr=params[4],
            layers=params[5],
            activation_func=params[6],
            max_epoch=params[7],
            dataset_name=dataset_name,
            save_dir=save_dir
        )

    total_time_taken = time.time() - total_start_time
    print(f"\nâœ… Hyperparameter search completed in {total_time_taken / 3600:.2f} hours.")

    # --- ä¿å­˜ã€åˆ†æå’Œç»˜åˆ¶ç»“æœ ---
    df_results = pd.DataFrame(results)
    df_results.to_excel(os.path.join(save_dir, 'full_search_results_2stage.xlsx'), index=False)

    analyze_and_save_summary(df_results, save_dir, dataset_name)
    plot_search_results(df_results, save_dir)


if __name__ == '__main__':
    main()